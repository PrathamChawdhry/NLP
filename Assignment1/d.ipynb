{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cmmcmcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Matrix Index: Index(['NUM', 'NOUN', 'DET', 'VERB', 'ADJ', '.', 'PUNCT', 'ADP', 'CONJ',\n",
      "       'PROPN', 'X', 'PRON', 'ADV', 'AUX', 'INTJ', 'CCONJ', 'PRT', 'PART',\n",
      "       'SCONJ', '_', 'SYM'],\n",
      "      dtype='object')\n",
      "Transition Matrix Columns: Index(['NUM', 'NOUN', 'DET', 'VERB', 'ADJ', '.', 'PUNCT', 'ADP', 'CONJ',\n",
      "       'PROPN', 'X', 'PRON', 'ADV', 'AUX', 'INTJ', 'CCONJ', 'PRT', 'PART',\n",
      "       'SCONJ', '_', 'SYM'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "# Load transition matrix\n",
    "transition_df = pd.read_csv(r\"C:\\Users\\mitta\\OneDrive - iiit-b\\Documents\\NLP\\Assignment1\\dataset\\transition_probability_matrix.csv\", index_col=0)\n",
    "\n",
    "# Load emission matrix\n",
    "emission_df = pd.read_csv(r\"C:\\Users\\mitta\\OneDrive - iiit-b\\Documents\\NLP\\Assignment1\\dataset\\emissive_probability_matrix.csv\", index_col=0)\n",
    "\n",
    "start_df= pd.read_csv(r\"C:\\Users\\mitta\\OneDrive - iiit-b\\Documents\\NLP\\Assignment1\\dataset\\start_probability_matrix.csv\", index_col=0)\n",
    "\n",
    "# Ensure index and column names are properly set\n",
    "print(\"Transition Matrix Index:\", transition_df.index)\n",
    "print(\"Transition Matrix Columns:\", transition_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_algorithm(words, transition_df, emission_df, start_df):\n",
    "    # words = sentence.split()\n",
    "  \n",
    "    pos_tags = list(transition_df.index)  # POS tag list\n",
    "    num_tags = len(pos_tags)\n",
    "    num_words = len(words)\n",
    "    \n",
    "    # Initialize DP tables\n",
    "    viterbi = np.zeros((num_tags, num_words))  \n",
    "    backpointer = np.zeros((num_tags, num_words), dtype=int)  \n",
    "    \n",
    "    # Initialization step\n",
    "    for i, tag in enumerate(pos_tags):\n",
    "        start_prob = start_df.loc[tag, 'START'] if tag in start_df.index else 1e-6\n",
    "        emission_prob = emission_df.loc[tag, words[0]] if words[0] in emission_df.columns else 1e-6\n",
    "        viterbi[i, 0] = start_prob * emission_prob\n",
    "    \n",
    "    # Recursion step\n",
    "    for t in range(1, num_words):\n",
    "        for i, tag in enumerate(pos_tags):\n",
    "            max_prob, max_state = max(\n",
    "                (viterbi[k, t-1] * transition_df.loc[prev_tag, tag] * (emission_df.loc[tag, words[t]] if words[t] in emission_df.columns else 1e-6), k)\n",
    "                if prev_tag in transition_df.index else (1e-6, k)\n",
    "                for k, prev_tag in enumerate(pos_tags)\n",
    "            )\n",
    "            viterbi[i, t] = max_prob\n",
    "            backpointer[i, t] = max_state\n",
    "    \n",
    "    # Traceback\n",
    "    best_path = []\n",
    "    best_last_state = np.argmax(viterbi[:, -1])\n",
    "    best_path.append(pos_tags[best_last_state])\n",
    "    \n",
    "    for t in range(num_words - 1, 0, -1):\n",
    "        best_last_state = backpointer[best_last_state, t]\n",
    "        best_path.insert(0, pos_tags[best_last_state])\n",
    "    \n",
    "    return list(zip(words, best_path))\n",
    "\n",
    "# # Example Usage\n",
    "# sentence = \"The industry has said\"\n",
    "# predicted_tags = viterbi_algorithm(sentence, transition_df, emission_df, start_df)\n",
    "# print(predicted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data= pd.read_csv(r\"C:\\Users\\mitta\\OneDrive - iiit-b\\Documents\\NLP\\Assignment1\\dataset\\TEST.csv\", header=None, names=['sentence'])\n",
    "test_data['sentence'] = test_data['sentence'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_data):\n",
    "    correct, total = 0, 0\n",
    "    for sentence in test_data['sentence']:\n",
    "       \n",
    "        words = [word for word,_ in sentence]\n",
    "        \n",
    "        actual_tags = [tag for _, tag in sentence]\n",
    "        predicted_tags = viterbi_algorithm(words, transition_df, emission_df,start_df)\n",
    "        correct += sum(p == a for p, a in zip(predicted_tags, actual_tags))\n",
    "        total += len(actual_tags)\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    print(\"Model Accuracy: \"+str(accuracy*100)+\"%\")\n",
    "\n",
    "evaluate(test_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
